#!/usr/bin/env python
from processing.DLProcessing import DLPreprocessing
from util.Config import Config
from multiprocessing import Pool
import multiprocessing as mp
import xarray as xr
import numpy as np
import argparse
import os


def main():
    """
    Main function to parse out configuration file (Config), a dictionary 
    of different model tunnings, for slicing model and observational data. 

    For a given number of parallel processesors, the model and observational 
    data are sliced each day with the model data separated by ensemble member. 
    """
    parser = argparse.ArgumentParser("hsdldata - Hagelslag Deep Learning Data Processor")
    parser.add_argument("config", help="Configuration file")
    parser.add_argument("-p", "--proc", type=int, default=1,help="Number of processors")
    parser.add_argument("-o", "--obs", action="store_true", help="Process observed tracks only")
    args = parser.parse_args()
    required = ['dates','start_hour','end_hour','ensemble_members','model_path', 
                'ensemble_name','mrms_path','mrms_variable','predictors',
                'model_map_file','hf_path','patch_radius','overlap_size',
                'model_type','train','mode']
    #Add attributes of dict to config
    config = Config(args.config, required_attributes=required)
    if not hasattr(config, "run_date_format"):
        config.run_date_format = "%Y%m%d-%H%M"
    if hasattr(config, "mask_file"):
        zero_mask = xr.open_dataset(config.mask_file)['usa_mask'].values
        config.mask = np.where(zero_mask.flatten()<1,np.nan,1).reshape(zero_mask.shape)
    else: config.mask=None

    for member in config.ensemble_members:
        member_path = '{0}/{1}'.format(config.hf_path,member)
        if not os.path.exists(member_path): os.makedirs(member_path)
    
    dlprocess = DLPreprocessing(config.train,config.ensemble_name,
        config.model_path,config.hf_path,config.patch_radius,
        config.overlap_size,config.run_date_format,
        config.predictors,config.start_hour,config.end_hour,
        config.model_type,config.mode,config.mask)

    #Process map data
    dlprocess.process_map_data(config.model_map_file)
    
    #Process obs and ensemble data with parallelization
    if args.obs or config.train is True:
        pool = Pool(25) #mp.cpu_count())
        for run_date in config.dates:
            pool.apply_async(dlprocess.process_observational_data,
            (run_date,config.mrms_variable,config.mrms_path))
        pool.close()
        pool.join()
    
    if not args.obs:
        pool = Pool(25) #mp.cpu_count())
        for run_date in config.dates:
            for member in config.ensemble_members:
                pool.apply_async(dlprocess.process_ensemble_member,
                (run_date,member,config.hf_path,config.model_map_file))
        pool.close()
        pool.join()
    
    return

if __name__ == "__main__":
    main()
