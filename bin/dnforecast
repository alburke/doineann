#!/usr/bin/env python
from util.make_proj_grids import make_proj_grids, read_ncar_map_file
from processing.DLModeler import DLModeler
from scipy.spatial import cKDTree
from util.Config import Config
from glob import glob
import pandas as pd
import xarray as xr
import numpy as np
import argparse
import h5py

def main():
    """
    Main function to parse out configuration file (Config), a dictionary 
    of different model tunnings, for slicing model and observational data. 

    For a given number of parallel processesors, the model and observational 
    data are sliced each day with the model data separated by ensemble member. 
    """
    parser = argparse.ArgumentParser("hsdata - Hagelslag Data Processor")
    parser.add_argument("config", help="Configuration file")
    parser.add_argument("-t", "--train", action="store_true", help="Train machine learning models.")
    parser.add_argument("-f", "--fore", action="store_true", help="Generate forecasts from machine learning models.")
    args = parser.parse_args()
    required = ['start_dates','end_dates','start_hour','end_hour','ensemble_members',
                'model_path','ensemble_name','predictors','model_map_file',
                'model_type','hf_path','forecast_grid_path','patch_radius',
                'num_examples','class_percentages'] 
    
    #Add attributes of dict to config
    config = Config(args.config, required_attributes=required)
    config.valid_hours = np.arange(config.start_hour, config.end_hour)
    if not hasattr(config, "run_date_format"): config.run_date_format = "%Y%m%d-%H"
    
    train_dates = pd.date_range(start=config.start_dates['train'],
            end=config.end_dates['train'],freq='1D'
            ).strftime(config.run_date_format)
        
    forecast_dates = pd.date_range(start=config.start_dates['forecast'],
            end=config.end_dates['forecast'],freq='1D'
            ).strftime(config.run_date_format)
        
    valid_dates = pd.date_range(start=config.start_dates['valid'],
            end=config.end_dates['valid'],freq='1D'
            ).strftime(config.run_date_format)
    
    model_args='{0}_{1}_{2}'.format(train_dates[0],
            train_dates[-1],config.num_examples)
    
    #Class to train and predict on given data
    dlmodel = DLModeler(config.model_path,config.hf_path,
        config.num_examples,config.class_percentages,config.predictors,
        model_args,config.model_type)
     
    #Train DL Models
    if args.train:
        for member in config.ensemble_members:
            dlmodel.train_models(member,train_dates,valid_dates)
    
    #Predict using trained DL models
    elif args.fore:
        total_map_shape,subset_map_shape,patch_map_conversion_indices,lon_grid,lat_grid = forecast_map_info(config)        
        for date in forecast_dates:
            for member in config.ensemble_members:
                print('\nPredicting {0} {1} data'.format(member,date))
                dlmodel.predict_model(member,patch_map_conversion_indices,total_map_shape,subset_map_shape,
                    [date],config.patch_radius,config.forecast_grid_path,lon_grid,lat_grid)
        
    return


def forecast_map_info(config):
    print('\nCreating cKDtree to map patches onto the total grid') 
    
    #Open mapfile over total domain
    proj_dict, grid_dict = read_ncar_map_file(config.model_map_file)
    mapping_data = make_proj_grids(proj_dict, grid_dict)
    total_map_shape =  mapping_data['lat'].shape
    
    #Create cKDtree to convert patch grid points to the total domain
    tree = cKDTree(np.c_[mapping_data['lon'].ravel(),mapping_data['lat'].ravel()])
    #del mapping_data

    #Open mapfile over subset domain (CONUS)
    subset_map_file = config.hf_path+'/HREFv2_map_data.h5'
    
    with h5py.File(subset_map_file,'r') as hf: 
        subset_map_data = hf['data'][()]
    subset_map_shape = subset_map_data.shape

    patch_map_conversion_indices = []
    overlap_pts = 4
    for patch in np.arange(subset_map_data.shape[1]):
        #Convert patch grid points to total grid using cKDtree
        _,map_conversion_inds = tree.query(
            #np.c_[subset_map_data[0,patch,:,:].ravel(),subset_map_data[1,patch,:,:].ravel()])
            np.c_[subset_map_data[0,patch,overlap_pts:-overlap_pts,overlap_pts:-overlap_pts].ravel(),
            subset_map_data[1,patch,overlap_pts:-overlap_pts,overlap_pts:-overlap_pts].ravel()])
        patch_map_conversion_indices.append(map_conversion_inds)
    print(np.shape(patch_map_conversion_indices))
    del subset_map_data
    return total_map_shape,subset_map_shape,patch_map_conversion_indices,mapping_data['lon'],mapping_data['lat']

if __name__ == "__main__":
    __spec__ = None
    main()

