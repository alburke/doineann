#!/usr/bin/env python
from util.make_proj_grids import make_proj_grids, read_ncar_map_file
from processing.DLDataEngineering  import DLDataEngineering
from sklearn.preprocessing import OneHotEncoder
from processing.DLModeler import DLModeler
from scipy.spatial import cKDTree
from util.Config import Config
from glob import glob
import pandas as pd
import numpy as np
import argparse
import h5py

def main():
    """
    Main function to parse out configuration file (Config), a dictionary 
    of different model tunnings, for slicing model and observational data. 

    For a given number of parallel processesors, the model and observational 
    data are sliced each day with the model data separated by ensemble member. 
    """
    parser = argparse.ArgumentParser("hsdata - Hagelslag Data Processor")
    parser.add_argument("config", help="Configuration file")
    parser.add_argument("-t", "--train", action="store_true", help="Train machine learning models.")
    parser.add_argument("-f", "--fore", action="store_true", help="Generate forecasts from machine learning models.")
    args = parser.parse_args()
    required = ['start_dates','end_dates','start_hour','end_hour','ensemble_members',
                'model_path','ensemble_name','storm_variables','potential_variables', 
                'model_map_file','hf_path','forecast_grid_path','patch_radius',
                'num_examples','class_percentages'] 
    
    #Add attributes of dict to config
    config = Config(args.config, required_attributes=required)
    config.valid_hours = np.arange(config.start_hour, config.end_hour)
    if not hasattr(config, "run_date_format"):
        config.run_date_format = "%Y%m%d-%H"
    config.forecast_variables = config.storm_variables + config.potential_variables
    if hasattr(config, "tendency_variables"):
        config.forecast_variables.extend(config.tendency_variables)
    #Shorten variable names
    long_forecast_variables = []
    for variable in config.forecast_variables:
        if "_" in variable and " " not in variable:
            variable_name= variable.split('_')[0].upper() + variable.split('_')[-1]
        elif "_" in variable:
            variable_name= ''.join([v[0].upper() for v in variable.split()]) + variable.split('_')[-1]
        elif " " in variable: variable_name= ''.join([v[0].upper() for v in variable.split()])
        else:variable_name = variable
        long_forecast_variables.append(variable_name)
    var_names = np.array(long_forecast_variables)
    
    #Class to read data and standardize
    dldataeng = DLDataEngineering(config.model_path,config.hf_path,
        config.start_dates,config.end_dates,config.num_examples,
        config.class_percentages,config.patch_radius,
        config.run_date_format,var_names)
    
    #Class to train and predict on the data
    dlmodel = DLModeler(config.model_path,
        config.start_dates['train'].strftime('%Y%m%d'),
        config.end_dates['train'].strftime('%Y%m%d'),var_names,
        config.num_examples,config.class_percentages)
    
    if args.train:
        for member in config.ensemble_members:
            train_models(config,dlmodel,dldataeng,member)
    elif args.fore:
        subset_map_data, map_conversion_inds = forecast_map_info()        
        forecast_dates = pd.date_range(start=config.start_dates['forecast'],
            end=config.end_dates['forecast'],freq='1D').strftime(config.run_date_format)
        for date in forecast_dates:
            for member in config.ensemble_members:
                print('\nPredicting {0} {1} data'.format(member,date))
                dlmodel.predict_model(member,subset_map_data,total_map_data,
                    date,dldataeng,config.patch_radius,
                    map_conversion_inds,config.forecast_grid_path)
    return

def train_models(config,dlmodel,dldataeng,member):
    """
    Function that reads and extracts pre-processed 2d member data 
    from an ensemble to train a convolutional neural net (cnn). 
    The model data is standardized before being input to the cnn, 
    with the observation data in the shape (# examples, # classes). 

    Args:
        config (object): configuration object 
        dlmodel (object): class object for creating/processing data for a cnn
        member (str): ensemble member data that trains a cnn
    """
    
    train_data, train_label = dldataeng.extract_training_data(member)
    #valid_data, valid_label = dldataeng.extract_validation_data(member)
    valid_data, valid_label = [],[]
    
    #onehot_encoder = OneHotEncoder(sparse=False,categories='auto')
    #encoded_label = onehot_encoder.fit_transform(train_label.reshape(-1, 1))
    
    #Train and save models predicting severe hail or no hail
    #dlmodel.train_CNN(member,(train_data,encoded_label,valid_data,valid_label))
    
    dlmodel.train_UNET(member,(train_data,train_label,valid_data,valid_label))
    return 

def forecast_map_info(config):
    print('\nCreating cKDtree to map patches onto the total grid') 
    #Open mapfile over total domain
    proj_dict, grid_dict = read_ncar_map_file(config.model_map_file)
    mapping_data = make_proj_grids(proj_dict, grid_dict)
    #Create cKDtree to convert patch grid points to the total domain
    tree = cKDTree(np.c_[mapping_data['lon'].ravel(),mapping_data['lat'].ravel()])
    #Open mapfile over subset domain (CONUS)
    subset_map_file = glob(config.hf_path+'/*map*.h5')[0] 
    subset_map_data = h5py.File(subset_map_file, 'r')['data']
    #Convert subset grid points to total grid using cKDtree
    _,map_conversion_inds = tree.query(np.c_[subset_data[0].ravel(),
            subset_data[1].ravel()])
    return subset_map_data,map_conversion_inds

if __name__ == "__main__":
    __spec__ = None
    main()

